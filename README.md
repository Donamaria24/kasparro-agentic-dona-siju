Kasparro Agentic Content Generation System

This project implements an agentic content generation pipeline using LangGraph and LangChain-style agents to generate structured product content such as:

- Product Page
- FAQs (â‰¥15 enforced)
- Product Comparison Page

The system is designed to work with an LLM provider (Gemini) and includes deterministic fallback logic to ensure reliability when LLM access is unavailable.

Architecture Overview

The system uses LangGraph to orchestrate multiple independent agents:

Product Input
â”‚
â–¼
Product Agent â”€â”€â–¶ Product Page JSON
â”‚
â–¼
FAQ Agent â”€â”€â”€â”€â”€â”€â–¶ FAQ JSON (â‰¥15 enforced)
â”‚
â–¼
Comparison Agent â–¶ Comparison Page JSON

Each agent:
- Receives shared state
- Performs validation and transformation
- Uses LLM if available
- Falls back to deterministic logic if LLM fails

Agents

1. Product Agent
- Generates a structured product page
- Validates required fields
- Guarantees non-empty `product_name`
- Output: `output/product_page.json`

2. FAQ Agent
- Generates at least 15 FAQs
- Uses LLM or deterministic fallback
- Enforces schema
- Output: `output/faq.json`

3. Comparison Agent
- Produces structured comparison content
- Ensures valid JSON output
- Output: `output/comparison_page.json`

LLM Fallback Strategy

If the LLM fails due to:
- Missing API key
- Rate limits
- Provider errors

The system automatically switches to deterministic logic.

This behavior is:
- Logged clearly in the terminal
- Fully documented
- Intentional and test-covered

âš ï¸ This ensures reliability without silent failures.

Project Structure

kasparro-agentic-dona-maria-siju/
â”œâ”€â”€ agents/
â”‚ â”œâ”€â”€ product_agent.py
â”‚ â”œâ”€â”€ faq_agent.py
â”‚ â”œâ”€â”€ comparison_agent.py
â”‚ â”œâ”€â”€ graph.py
â”‚ â””â”€â”€ state.py
â”‚
â”œâ”€â”€ schemas/
â”‚ â”œâ”€â”€ product_schema.py
â”‚ â”œâ”€â”€ faq_schema.py
â”‚ â””â”€â”€ comparison_schema.py
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ product_input.py
â”‚
â”œâ”€â”€ output/
â”‚ â”œâ”€â”€ product_page.json
â”‚ â”œâ”€â”€ faq.json
â”‚ â””â”€â”€ comparison_page.json
â”‚
â”œâ”€â”€ tests/
â”‚ â”œâ”€â”€ test_product_page.py
â”‚ â”œâ”€â”€ test_faq.py
â”‚ â””â”€â”€ test_comparison.py
â”‚
â”œâ”€â”€ docs/
â”‚ â””â”€â”€ projectdocumentation.md
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

Installation

python -m venv venv
venv\Scripts\activate
python -m pip install -r requirements.txt

Run the System
python -B main.py

Expected output:
ğŸ“ Output written to /output
âœ… Content generation completed successfully

Run Tests
python -m pytest

All tests must pass:
Schema validation
FAQ count enforcement
Product name validation
Output existence

Design Tradeoffs
This system prioritizes reliability over external dependency availability. When LLM access is unavailable, deterministic fallbacks ensure consistent outputs while preserving structural guarantees. Advanced features such as caching, rate limiting, and security hardening were intentionally scoped out to focus on correctness, validation, and agent orchestration.